## 책 읽고 리뷰 
- ch03.1 ~ 03.2
- 코드 중심으로 실습이 필요.

### 책 내용에서 확인해야할 것
- 핵심키워드 : 재귀
- '웹스크래핑'과 '웹크롤링' 용어를 구분해서 작성하자
  - 웹스크래핑 : 
  - 웹크롤링: 
  
  [] 추가 설명 필요

> 웹 크롤러를 사용할 때는 반드시 대역폭에 세심한 주의를 기울여야 하며, 타깃 서버의 부하를 줄일 방법을 강구해야합니다. (p.53)

> 위키백과의 서버 부하에 대한 대책은? (...)기부 하십시오. (p.54)
- python 1000번만 재귀호출됨
- 예외처리 중요하다! (책 샘플코드에는 예외처리가 없음)

> 웹사이트 전체 크롤링은 언제 유용하고, 언제 손해일까요? 
  - 사이트맵 생성 / 데이터 수집
> 같은 페이지를 두 번 크롤링하지 않으려면 발견되는 내부 링크가 모두 일정한 형식을 취하고,프로그램이 동작하는 동안 계속 유지되는 리스트에 보관하는 게 대단히 중요합니다. 새로운 링크만 탐색하고 거기서 다른 링크를 검색해야 합니다.

> 파이썬은 기본적으로 재귀 호출을 1,000회로 제한합니다.(...) 멈추는 일을 막으려면 재귀 카운터를 삽입하거나 다른 방법을 강구해야 합니다.

> 결국 필자는 URL이 너무 우스꽝스러워 보이지는 않는지, 무한 루프로 보이는 반복된 조각이 들어 있지는 않는지 체크하는 코드를 삽입해야 했습니다. 이렇게 하지 않고 밤새 돌아가도록 내버려뒀더라면 금새 정지했을 겁니다.

> 이런 일을 가장 잘하기 위해 첫 번째 할 일은 사이트의 페이지 몇 개를 살펴보며 패턴을 찾는 일입니다.

### 다음 시간에 할 일
- ch3 마저 읽기
- python 예외처리 공부하기 - HeadFirst Python(개정판 2017)
- 정규표현식 좋은 자료 찾기

